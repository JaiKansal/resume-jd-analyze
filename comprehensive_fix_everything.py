#!/usr/bin/env python3
"""
COMPREHENSIVE FIX EVERYTHING SCRIPT
Fixes every single issue found in the diagnostic scan
"""

import os
import json
import logging
import sqlite3
from pathlib import Path

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

class ComprehensiveFixer:
    def __init__(self):
        self.fixes_applied = []
        self.errors = []
    
    def log_fix(self, component, action):
        """Log a fix that was applied"""
        self.fixes_applied.append(f"{component}: {action}")
        logger.info(f"‚úÖ {component}: {action}")
    
    def log_error(self, component, error):
        """Log an error during fixing"""
        self.errors.append(f"{component}: {error}")
        logger.error(f"‚ùå {component}: {error}")
    
    def fix_requirements_txt(self):
        """Fix requirements.txt with all necessary packages"""
        logger.info("üîß Fixing requirements.txt...")
        
        requirements_content = """streamlit>=1.28.0
pandas>=1.5.0
python-dotenv>=1.0.0
bcrypt>=4.0.0
psycopg2-binary>=2.9.0
reportlab>=4.0.0
PyPDF2>=3.0.0
requests>=2.28.0
python-multipart>=0.0.6
pydantic>=2.0.0
email-validator>=2.0.0
Pillow>=9.0.0
numpy>=1.21.0
matplotlib>=3.5.0
seaborn>=0.11.0
plotly>=5.0.0
altair>=4.2.0
"""
        
        try:
            with open('requirements.txt', 'w') as f:
                f.write(requirements_content)
            self.log_fix("Requirements", "Updated with all necessary packages")
        except Exception as e:
            self.log_error("Requirements", f"Failed to update: {e}")
    
    def fix_streamlit_secrets(self):
        """Create Streamlit secrets file"""
        logger.info("üîß Creating Streamlit secrets...")
        
        # Ensure .streamlit directory exists
        streamlit_dir = Path('.streamlit')
        streamlit_dir.mkdir(exist_ok=True)
        
        # Read from .env file
        env_vars = {}
        if Path('.env').exists():
            with open('.env', 'r') as f:
                for line in f:
                    if '=' in line and not line.startswith('#'):
                        key, value = line.strip().split('=', 1)
                        env_vars[key] = value.strip("'\"")
        
        secrets_content = f"""# Streamlit Cloud Secrets - AUTO GENERATED
# Copy this content to your Streamlit Cloud app secrets

# Perplexity API for AI Analysis
PERPLEXITY_API_KEY = "{env_vars.get('PERPLEXITY_API_KEY', 'your_perplexity_api_key_here')}"

# Razorpay Payment Gateway
RAZORPAY_KEY_ID = "{env_vars.get('RAZORPAY_KEY_ID', 'your_razorpay_key_id')}"
RAZORPAY_KEY_SECRET = "{env_vars.get('RAZORPAY_KEY_SECRET', 'your_razorpay_secret')}"

# Database Configuration
DATABASE_URL = "{env_vars.get('DATABASE_URL', 'sqlite:///data/app.db')}"

# App Configuration
ENVIRONMENT = "production"
SECRET_KEY = "{env_vars.get('SECRET_KEY', 'your-secret-key-change-in-production')}"

# Feature Flags
ENABLE_ANALYTICS = true
ENABLE_PAYMENTS = true
ENABLE_REPORT_HISTORY = true
ENABLE_WATERMARKS = true
"""
        
        try:
            with open('.streamlit/secrets.toml', 'w') as f:
                f.write(secrets_content)
            self.log_fix("Streamlit Secrets", "Created secrets.toml with environment variables")
        except Exception as e:
            self.log_error("Streamlit Secrets", f"Failed to create: {e}")
    
    def fix_streamlit_config(self):
        """Fix Streamlit configuration"""
        logger.info("üîß Fixing Streamlit config...")
        
        config_content = """[global]
developmentMode = false
showWarningOnDirectExecution = false

[server]
headless = true
enableCORS = false
enableXsrfProtection = false
maxUploadSize = 200
port = 8501

[browser]
gatherUsageStats = false
serverAddress = "0.0.0.0"

[theme]
primaryColor = "#FF6B35"
backgroundColor = "#FFFFFF"
secondaryBackgroundColor = "#F0F2F6"
textColor = "#262730"
font = "sans serif"

[client]
showErrorDetails = false
"""
        
        try:
            with open('.streamlit/config.toml', 'w') as f:
                f.write(config_content)
            self.log_fix("Streamlit Config", "Updated config.toml with optimal settings")
        except Exception as e:
            self.log_error("Streamlit Config", f"Failed to update: {e}")
    
    def fix_packages_txt(self):
        """Fix packages.txt for system dependencies"""
        logger.info("üîß Fixing packages.txt...")
        
        packages_content = """sqlite3
libsqlite3-dev
python3-dev
build-essential
"""
        
        try:
            with open('packages.txt', 'w') as f:
                f.write(packages_content)
            self.log_fix("System Packages", "Updated packages.txt with system dependencies")
        except Exception as e:
            self.log_error("System Packages", f"Failed to update: {e}")
    
    def fix_app_py_main_block(self):
        """Remove problematic main block from app.py"""
        logger.info("üîß Fixing app.py main block...")
        
        try:
            with open('app.py', 'r') as f:
                content = f.read()
            
            # Remove main block if it exists
            if 'if __name__ == "__main__":' in content:
                lines = content.split('\n')
                new_lines = []
                skip_main = False
                
                for line in lines:
                    if 'if __name__ == "__main__":' in line:
                        skip_main = True
                        new_lines.append('# Main block removed for Streamlit Cloud compatibility')
                        continue
                    
                    if skip_main and line.strip() and not line.startswith('    ') and not line.startswith('\t'):
                        skip_main = False
                    
                    if not skip_main:
                        new_lines.append(line)
                
                with open('app.py', 'w') as f:
                    f.write('\n'.join(new_lines))
                
                self.log_fix("App.py", "Removed main block for Streamlit Cloud compatibility")
            else:
                self.log_fix("App.py", "No main block found - already compatible")
                
        except Exception as e:
            self.log_error("App.py", f"Failed to fix main block: {e}")
    
    def fix_database_schema(self):
        """Ensure database schema is complete and correct"""
        logger.info("üîß Fixing database schema...")
        
        try:
            # Ensure data directory exists
            Path('data').mkdir(exist_ok=True)
            
            conn = sqlite3.connect('data/app.db')
            cursor = conn.cursor()
            
            # Complete schema with all necessary tables and columns
            schema_sql = """
            -- Users table with complete schema
            CREATE TABLE IF NOT EXISTS users (
                id TEXT PRIMARY KEY,
                email TEXT UNIQUE NOT NULL,
                password_hash TEXT NOT NULL,
                first_name TEXT,
                last_name TEXT,
                company_name TEXT,
                role TEXT DEFAULT 'individual',
                phone TEXT,
                country TEXT,
                timezone TEXT DEFAULT 'UTC',
                email_verified INTEGER DEFAULT 0,
                email_verification_token TEXT,
                password_reset_token TEXT,
                password_reset_expires TIMESTAMP,
                last_login TIMESTAMP,
                login_count INTEGER DEFAULT 0,
                is_active INTEGER DEFAULT 1,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            
            -- Analysis sessions with complete schema
            CREATE TABLE IF NOT EXISTS analysis_sessions (
                id TEXT PRIMARY KEY,
                user_id TEXT NOT NULL,
                team_id TEXT,
                session_type VARCHAR(50) DEFAULT 'single',
                resume_count INTEGER DEFAULT 1,
                job_description_count INTEGER DEFAULT 1,
                resume_filename TEXT,
                score INTEGER,
                match_category TEXT,
                analysis_result TEXT,
                processing_time_seconds REAL,
                api_cost_usd REAL,
                tokens_used INTEGER,
                status VARCHAR(20) DEFAULT 'completed',
                error_message TEXT,
                metadata TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users (id)
            );
            
            -- Analysis reports table
            CREATE TABLE IF NOT EXISTS analysis_reports (
                id TEXT PRIMARY KEY,
                user_id TEXT NOT NULL,
                title TEXT NOT NULL,
                content TEXT NOT NULL,
                analysis_type TEXT DEFAULT 'resume_jd_match',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                metadata JSON,
                FOREIGN KEY (user_id) REFERENCES users (id)
            );
            
            -- Engagement events with both timestamp columns
            CREATE TABLE IF NOT EXISTS engagement_events (
                id TEXT PRIMARY KEY,
                user_id TEXT NOT NULL,
                event_type TEXT NOT NULL,
                event_data TEXT,
                page_path TEXT,
                session_id TEXT,
                parameters TEXT,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users (id)
            );
            
            -- Subscriptions table
            CREATE TABLE IF NOT EXISTS subscriptions (
                id TEXT PRIMARY KEY,
                user_id TEXT NOT NULL,
                plan_id TEXT NOT NULL,
                status TEXT DEFAULT 'active',
                current_period_start TIMESTAMP,
                current_period_end TIMESTAMP,
                cancel_at_period_end INTEGER DEFAULT 0,
                canceled_at TIMESTAMP,
                trial_start TIMESTAMP,
                trial_end TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users (id)
            );
            
            -- Plans table
            CREATE TABLE IF NOT EXISTS plans (
                id TEXT PRIMARY KEY,
                name TEXT NOT NULL,
                plan_type TEXT NOT NULL,
                price_monthly REAL,
                price_yearly REAL,
                features TEXT,
                analysis_limit INTEGER,
                is_active INTEGER DEFAULT 1,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            
            -- Create indexes for performance
            CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);
            CREATE INDEX IF NOT EXISTS idx_analysis_sessions_user_id ON analysis_sessions(user_id);
            CREATE INDEX IF NOT EXISTS idx_analysis_reports_user_id ON analysis_reports(user_id);
            CREATE INDEX IF NOT EXISTS idx_engagement_events_user_id ON engagement_events(user_id);
            CREATE INDEX IF NOT EXISTS idx_subscriptions_user_id ON subscriptions(user_id);
            """
            
            # Execute schema
            cursor.executescript(schema_sql)
            
            # Insert default plans if they don't exist
            cursor.execute("SELECT COUNT(*) FROM plans")
            if cursor.fetchone()[0] == 0:
                default_plans = [
                    ('free', 'Free Plan', 'FREE', 0, 0, '{"analyses_per_month": 3, "basic_features": true}', 3, 1),
                    ('professional', 'Professional Plan', 'PROFESSIONAL', 19, 190, '{"unlimited_analyses": true, "premium_features": true, "priority_support": true}', -1, 1),
                    ('business', 'Business Plan', 'BUSINESS', 99, 990, '{"unlimited_analyses": true, "team_features": true, "api_access": true, "priority_support": true}', -1, 1)
                ]
                
                cursor.executemany("""
                    INSERT INTO plans (id, name, plan_type, price_monthly, price_yearly, features, analysis_limit, is_active)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, default_plans)
            
            conn.commit()
            conn.close()
            
            self.log_fix("Database Schema", "Complete schema created with all tables and indexes")
            
        except Exception as e:
            self.log_error("Database Schema", f"Failed to fix: {e}")
    
    def fix_startup_py(self):
        """Ensure startup.py is properly configured"""
        logger.info("üîß Fixing startup.py...")
        
        startup_content = '''"""
Startup initialization for Resume + JD Analyzer
Ensures proper environment setup for Streamlit Cloud deployment
"""

import os
import sys
from pathlib import Path

# Add project root to Python path
project_root = Path(__file__).parent.absolute()
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# Set environment variables for Streamlit Cloud
os.environ.setdefault('PYTHONPATH', str(project_root))
os.environ.setdefault('STREAMLIT_SERVER_HEADLESS', 'true')
os.environ.setdefault('STREAMLIT_SERVER_ENABLE_CORS', 'false')

# Initialize logging
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)
logger.info("üöÄ Startup initialization completed")
logger.info(f"üìÅ Project root: {project_root}")
logger.info(f"üêç Python path: {sys.path[:3]}...")

# Ensure data directory exists
data_dir = project_root / 'data'
data_dir.mkdir(exist_ok=True)
logger.info(f"üìä Data directory: {data_dir}")
'''
        
        try:
            with open('startup.py', 'w') as f:
                f.write(startup_content)
            self.log_fix("Startup", "Updated startup.py with proper initialization")
        except Exception as e:
            self.log_error("Startup", f"Failed to update: {e}")
    
    def create_deployment_guide(self):
        """Create comprehensive deployment guide"""
        logger.info("üîß Creating deployment guide...")
        
        guide_content = """# üöÄ STREAMLIT CLOUD DEPLOYMENT GUIDE

## CRITICAL: Complete This Checklist Before Deployment

### ‚úÖ Pre-Deployment Checklist

1. **Repository Setup**
   - [ ] All changes committed and pushed to GitHub
   - [ ] Repository is public or Streamlit Cloud has access
   - [ ] Main branch is up to date

2. **Required Files Present**
   - [ ] `app.py` (main application file)
   - [ ] `requirements.txt` (Python dependencies)
   - [ ] `packages.txt` (system dependencies)
   - [ ] `.streamlit/config.toml` (Streamlit configuration)
   - [ ] `.streamlit/secrets.toml` (for local testing only)

3. **Streamlit Cloud Configuration**
   - [ ] App created in Streamlit Cloud dashboard
   - [ ] Repository connected: `JaiKansal/resume-jd-analyze`
   - [ ] Branch set to: `main`
   - [ ] Main file set to: `app.py`

### üîê CRITICAL: Streamlit Cloud Secrets

**You MUST add these secrets in Streamlit Cloud dashboard:**

```toml
# Go to your app settings ‚Üí Secrets ‚Üí Paste this content

PERPLEXITY_API_KEY = "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"
RAZORPAY_KEY_ID = "rzp_live_gBOm5l3scvXYjP"
RAZORPAY_KEY_SECRET = "ptem0kGjg2xW9zWMcGWp2aJz"
DATABASE_URL = "sqlite:///data/app.db"
ENVIRONMENT = "production"
SECRET_KEY = "your-secret-key-change-in-production"
ENABLE_ANALYTICS = true
ENABLE_PAYMENTS = true
ENABLE_REPORT_HISTORY = true
ENABLE_WATERMARKS = true
```

### üö® USER DATA WARNING

**CRITICAL**: Your current SQLite database will NOT persist on Streamlit Cloud!

- ‚ùå **All 10 users will be lost** on every deployment
- ‚ùå **Analysis history will be wiped**
- ‚ùå **Subscriptions will be reset**

**SOLUTION**: Set up PostgreSQL database:

1. **Create PostgreSQL Database**:
   - Go to https://neon.tech (free tier)
   - Create new project
   - Copy connection string

2. **Update Streamlit Cloud Secrets**:
   ```toml
   DATABASE_URL = "postgresql://username:password@hostname:5432/database"
   ```

3. **Restore Users**:
   ```bash
   python3 import_to_postgresql.py
   ```

### üìã Deployment Steps

1. **Commit All Changes**:
   ```bash
   git add .
   git commit -m "üöÄ Ready for Streamlit Cloud deployment"
   git push origin main
   ```

2. **Deploy to Streamlit Cloud**:
   - Go to https://share.streamlit.io/
   - Click "New app"
   - Repository: `JaiKansal/resume-jd-analyze`
   - Branch: `main`
   - Main file path: `app.py`
   - Click "Deploy!"

3. **Add Secrets** (CRITICAL):
   - Go to app settings ‚Üí Secrets
   - Paste the secrets configuration above
   - Save secrets

4. **Wait for Deployment**:
   - Initial deployment: 5-10 minutes
   - Watch logs for errors
   - App will be available at: `https://resume-jd-analyze.streamlit.app`

### üß™ Post-Deployment Testing

1. **Basic Functionality**:
   - [ ] App loads without errors
   - [ ] User registration works
   - [ ] User login works
   - [ ] Analysis functionality works
   - [ ] Download buttons work

2. **Fixed Issues**:
   - [ ] Analysis history displays properly
   - [ ] Downloads don't cause UI issues
   - [ ] No database timestamp errors
   - [ ] No watermark Canvas errors

### üÜò Troubleshooting

**If deployment fails**:
1. Check Streamlit Cloud logs
2. Verify all secrets are added
3. Ensure repository access is granted
4. Check requirements.txt for missing packages

**If app loads but has errors**:
1. Check browser console for JavaScript errors
2. Verify API keys in secrets
3. Check database connectivity
4. Review Streamlit Cloud logs

### üìû Support

If issues persist:
1. Check diagnostic report: `diagnostic_report.json`
2. Review deployment logs in Streamlit Cloud
3. Verify all files are committed and pushed
4. Ensure secrets are properly configured

---

**üéØ GOAL**: Get your app running on Streamlit Cloud with all fixes applied and users preserved through PostgreSQL migration.
"""
        
        try:
            with open('STREAMLIT_DEPLOYMENT_GUIDE.md', 'w') as f:
                f.write(guide_content)
            self.log_fix("Deployment Guide", "Created comprehensive deployment guide")
        except Exception as e:
            self.log_error("Deployment Guide", f"Failed to create: {e}")
    
    def create_final_commit_script(self):
        """Create script to commit all fixes"""
        logger.info("üîß Creating final commit script...")
        
        commit_script = '''#!/bin/bash
# Final commit script - commits all fixes for Streamlit Cloud deployment

echo "üöÄ Preparing final commit for Streamlit Cloud deployment..."

# Add all fixed files
git add .
git add -f .streamlit/secrets.toml  # Force add secrets for local testing
git add -f data/app.db              # Force add database with restored users

# Commit with comprehensive message
git commit -m "üöÄ STREAMLIT CLOUD READY: Complete fix for all issues

‚úÖ FIXES APPLIED:
- Updated requirements.txt with all necessary packages
- Created .streamlit/secrets.toml with environment variables  
- Fixed .streamlit/config.toml with optimal settings
- Updated packages.txt with system dependencies
- Removed problematic main block from app.py
- Fixed complete database schema with all tables
- Updated startup.py with proper initialization
- Created comprehensive deployment guide

üîß ISSUES RESOLVED:
- Analysis history not showing ‚Üí Fixed UI components and database queries
- Analysis disappearing on download ‚Üí Fixed state management
- Database timestamp errors ‚Üí Fixed column names and schema
- Watermark Canvas errors ‚Üí Fixed method calls
- Missing Streamlit/pandas imports ‚Üí Updated requirements.txt
- Missing secrets configuration ‚Üí Created secrets.toml
- Streamlit Cloud compatibility ‚Üí Removed main block, added proper config

üóÑÔ∏è DATABASE STATUS:
- 10 users restored and ready
- 1 analysis session preserved
- Complete schema with all required tables
- Indexes created for performance

‚ö†Ô∏è  CRITICAL NEXT STEPS:
1. Push this commit to GitHub
2. Deploy to Streamlit Cloud
3. Add secrets in Streamlit Cloud dashboard
4. Set up PostgreSQL for permanent user persistence

Ready for production deployment!"

echo "‚úÖ Commit created. Run 'git push origin main' to deploy!"
'''
        
        try:
            with open('final_commit.sh', 'w') as f:
                f.write(commit_script)
            
            # Make script executable
            os.chmod('final_commit.sh', 0o755)
            
            self.log_fix("Commit Script", "Created final commit script")
        except Exception as e:
            self.log_error("Commit Script", f"Failed to create: {e}")
    
    def run_comprehensive_fix(self):
        """Run all fixes"""
        logger.info("üöÄ STARTING COMPREHENSIVE FIX - EVERYTHING")
        logger.info("=" * 60)
        
        # Apply all fixes
        self.fix_requirements_txt()
        self.fix_streamlit_secrets()
        self.fix_streamlit_config()
        self.fix_packages_txt()
        self.fix_app_py_main_block()
        self.fix_database_schema()
        self.fix_startup_py()
        self.create_deployment_guide()
        self.create_final_commit_script()
        
        # Generate final report
        logger.info("\n" + "=" * 60)
        logger.info("üéâ COMPREHENSIVE FIX COMPLETE")
        logger.info("=" * 60)
        
        logger.info(f"‚úÖ FIXES APPLIED: {len(self.fixes_applied)}")
        for fix in self.fixes_applied:
            logger.info(f"   ‚úÖ {fix}")
        
        if self.errors:
            logger.info(f"\n‚ùå ERRORS ENCOUNTERED: {len(self.errors)}")
            for error in self.errors:
                logger.error(f"   ‚ùå {error}")
        
        logger.info("\nüöÄ NEXT STEPS:")
        logger.info("1. Review STREAMLIT_DEPLOYMENT_GUIDE.md")
        logger.info("2. Run: ./final_commit.sh")
        logger.info("3. Run: git push origin main")
        logger.info("4. Deploy to Streamlit Cloud")
        logger.info("5. Add secrets in Streamlit Cloud dashboard")
        
        return len(self.errors) == 0

def main():
    """Run comprehensive fix"""
    fixer = ComprehensiveFixer()
    success = fixer.run_comprehensive_fix()
    
    if success:
        logger.info("\nüéâ ALL FIXES APPLIED SUCCESSFULLY!")
        logger.info("Your app is now ready for Streamlit Cloud deployment!")
        return True
    else:
        logger.error("\nüö® SOME FIXES FAILED!")
        logger.error("Review the errors above and fix manually.")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)